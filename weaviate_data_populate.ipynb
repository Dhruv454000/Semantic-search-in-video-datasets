{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "540b2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import json\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url = \"\",  # Replace with your endpoint\n",
    "    auth_client_secret=weaviate.AuthApiKey(api_key=\"\"),  # Replace w/ your Weaviate instance API key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10f0168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from sentence-transformers) (4.30.2)\n",
      "Requirement already satisfied: tqdm in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from sentence-transformers) (1.25.0)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk (from sentence-transformers)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: filelock in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: sympy in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
      "Collecting click (from nltk->sentence-transformers)\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib (from nltk->sentence-transformers)\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/dhruv/miniconda3/envs/Semantic-search/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=1ab0e6d4aa6e28d54691a139f66107a72c0305c3bf1b01f775395f1b68a08467\n",
      "  Stored in directory: /export/home/dhruv/.cache/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, click, scikit-learn, nltk, sentence-transformers\n",
      "Successfully installed click-8.1.3 joblib-1.2.0 nltk-3.8.1 scikit-learn-1.2.2 scipy-1.11.0 sentence-transformers-2.2.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a944083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def get_embedding(text):\n",
    "    embeddings = model.encode(sentences)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_obj = {\n",
    "    \"class\": \"Video_description\",\n",
    "    \"vectorizer\": \"text2vec-huggingface\",  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-huggingface\": {\n",
    "            \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",  # Can be any public or private Hugging Face model.\n",
    "            \"options\": {\n",
    "                \"waitForModel\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "client.schema.create_class(class_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c442a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "input_directory = 'output_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c729c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [f for f in os.listdir(input_directory) if f.endswith('.json')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9553bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in json_files:\n",
    "    input_file = os.path.join(input_directory, file_name)\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)  \n",
    "        metadata = data['metadata']['file']\n",
    "        video_id = data['metadata']['text_id'][3:]\n",
    "        with client.batch(batch_size=100) as batch:\n",
    "            \n",
    "            for sent in data['sentences']:\n",
    "                embedding = model.encode(sent['sentence'])\n",
    "                properties = {\n",
    "                   \"text\": sent['sentence'],\n",
    "                   \"starttime\" : sent['starttime'],\n",
    "                   \"endtime\" : sent['endtime'],\n",
    "                   \"metadata\" : metadata,\n",
    "                   \"video_id\" : video_id\n",
    "                }\n",
    "\n",
    "                client.batch.add_data_object(\n",
    "                    properties,\n",
    "                    \"Video_description\",\n",
    "                    vector = embedding\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6345efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"Get\": {\n",
      "            \"Video_description\": [\n",
      "                {\n",
      "                    \"endtime\": \"134.15\",\n",
      "                    \"metadata\": \"/db/tv/2016/2016-02/2016-02-02/2016-02-02_1500_US_KABC_Good_Morning_America.txt\",\n",
      "                    \"starttime\": \"131.23\",\n",
      "                    \"text\": \"Big Questions Right now can donald trump bounce back from a loss\",\n",
      "                    \"video_id\": \"4b9b3cd8_c9c6_11e5_b5ec_089e01ba0335\"\n",
      "                },\n",
      "                {\n",
      "                    \"endtime\": \"231.40\",\n",
      "                    \"metadata\": \"/db/tv/2016/2016-02/2016-02-02/2016-02-02_1500_US_KABC_Good_Morning_America.txt\",\n",
      "                    \"starttime\": \"225.12\",\n",
      "                    \"text\": \"Donald Trump called the republican front-runner for more than six months now has a new title loser .\",\n",
      "                    \"video_id\": \"4b9b3cd8_c9c6_11e5_b5ec_089e01ba0335\"\n",
      "                },\n",
      "                {\n",
      "                    \"endtime\": \"903.00\",\n",
      "                    \"metadata\": \"/db/tv/2016/2016-02/2016-02-02/2016-02-02_1500_US_KABC_Good_Morning_America.txt\",\n",
      "                    \"starttime\": \"901.77\",\n",
      "                    \"text\": \"Donald Trump has to win .\",\n",
      "                    \"video_id\": \"4b9b3cd8_c9c6_11e5_b5ec_089e01ba0335\"\n",
      "                },\n",
      "                {\n",
      "                    \"endtime\": \"516.94\",\n",
      "                    \"metadata\": \"/db/tv/2016/2016-02/2016-02-02/2016-02-02_1800_US_CNN_Wolf.txt\",\n",
      "                    \"starttime\": \"516.30\",\n",
      "                    \"text\": \"He narrowly lost .\",\n",
      "                    \"video_id\": \"879965fc_c9df_11e5_bf1a_089e01ba0338\"\n",
      "                },\n",
      "                {\n",
      "                    \"endtime\": \"24.68\",\n",
      "                    \"metadata\": \"/db/tv/2016/2016-02/2016-02-02/2016-02-02_1500_US_KABC_Good_Morning_America.txt\",\n",
      "                    \"starttime\": \"23.36\",\n",
      "                    \"text\": \"Trump humbled in defeat .\",\n",
      "                    \"video_id\": \"4b9b3cd8_c9c6_11e5_b5ec_089e01ba0335\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url = \"\",  # Replace with your endpoint\n",
    "    auth_client_secret=weaviate.AuthApiKey(api_key=\"\"),  # Replace w/ your Weaviate instance API key\n",
    ")\n",
    "\n",
    "# Define the input sentence for which you want to find similar sentences\n",
    "# input_sentence = \"Donald trump after losing\"\n",
    "\n",
    "nearText = {\"concepts\": [\"Donald trump after losing\"]}\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Video_description\", [\"text\", \"starttime\", \"endtime\", \"metadata\",\"video_id\"])\n",
    "    .with_near_text(nearText)\n",
    "    .with_limit(5)\n",
    "    .do()\n",
    ")\n",
    "print(json.dumps(response, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845202e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
